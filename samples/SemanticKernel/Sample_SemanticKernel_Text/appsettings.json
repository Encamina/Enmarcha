{
  "SemanticKernelOptions": {
    "ChatModelName": "gpt-35-turbo", // Name (sort of a unique identifier) of the model to use for chat
    "ChatModelDeploymentName": "gpt-35-turbo", // Model deployment name on the LLM (for example OpenAI) to use for chat
    "Endpoint": "https://your-url.openai.azure.com/", // Uri for an LLM resource (like OpenAI). This should include protocol and hostname.
    "Key": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", // Key credential used to authenticate to an LLM resource
    // ....
  }
}
